
# ğŸª™ Coin Detection & Segmentation API ğŸš€

This project focuses on **fine-tuning a Mask R-CNN model** for coin detection & segmentation using a COCO-style dataset, and **deploying it via a FastAPI backend with Docker Compose orchestration**.

---

## ğŸ“‚ Project Directory Structure

```
challenge_1/
â”œâ”€â”€ .env
â”œâ”€â”€ fine_tune_notebook.ipynb                 # Jupyter notebook for fine-tuning Mask R-CNN
â”œâ”€â”€ app/                                     # FastAPI application for inference
â”‚   â”œâ”€â”€ docker-compose.yaml                  # Docker Compose file for multi-container setup
â”‚   â”œâ”€â”€ Dockerfile                           # API container Dockerfile
â”‚   â”œâ”€â”€ main.py                              # FastAPI entrypoint
â”‚   â”œâ”€â”€ models.py                            # Pydantic models for API input/output
â”‚   â”œâ”€â”€ requirements.txt                     # Python dependencies
â”‚   â”œâ”€â”€ model/                               # Trained model artifacts (.pth files)
â”‚   â”œâ”€â”€ utils/                               # Helper modules
â”‚   â”‚   â”œâ”€â”€ ml/detection.py                  # Core detection logic (inference)
â”‚   â”‚   â”œâ”€â”€ mongo_client.py                  # MongoDB connector
â”‚       â””â”€â”€ minio_client.py                  # MinIO (object storage) connector
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ local/                               # Local infra bootstrap scripts
â”‚   â”‚   â”œâ”€â”€ init_minio.sh
â”‚   â”‚   â”œâ”€â”€ init_mongo.sh
â”‚   â”‚   â””â”€â”€ init_redis.sh
â”‚   â””â”€â”€ torchserve/                          # TorchServe deployment scripts and MAR files
â”‚       â”œâ”€â”€ create_mar.sh
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ init_torchserve.sh
â”‚       â”œâ”€â”€ maskrcnn_handler.py
â”‚       â””â”€â”€ model-store/
â”‚           â”œâ”€â”€ dummy.mar
â”‚           â””â”€â”€ maskrcnn_v2.mar
```

---

## ğŸ‹ï¸â€â™‚ï¸ Model Training (Fine-Tuning)

- Located in: `fine_tune_notebook.ipynb`
- Uses `maskrcnn_resnet50_fpn_v2` from torchvision
- Trained on COCO-formatted coin dataset with 70:30 data split
- Outputs `.pth` models saved in `/app/model/`

---

## ğŸ§ª API Inference (FastAPI App)

- Located in: `/app/main.py`
- Loads fine-tuned `.pth` models
- Performs object detection and segmentation
- Persists detection metadata to **MongoDB**
- Stores detection result images in **MinIO Object Storage**
- Optional caching layer using **Redis** (TTL = 1 hour)

---

## ğŸ³ Docker Compose Setup

This project uses **MongoDB**, **MinIO**, **Redis**, and the **FastAPI app**. Launch all containers:

```bash
cd app
docker-compose up --build
```

Services:
- MongoDB â†’ `localhost:27017`
- MinIO â†’ `localhost:9000` (console: `localhost:9001`)
- Redis â†’ `localhost:6379`
- FastAPI â†’ `localhost:8000`

---

## ğŸš« Ignore Files (Optional .gitignore Additions)

```
__pycache__/
.ipynb_checkpoints/
*.pth
.env
```

---

## âœ… TODO / Next Steps

- [ ] Improve model evaluation metrics (e.g., mAP, IoU) on validation split
- [ ] Add health check endpoints for services
- [ ] Integrate TorchServe API deployment

---
